{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84daec9e-7ddc-435b-bb2c-9b5c7dc49aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install -q datasets\n",
    "!pip install -q scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e405a686-f063-4aab-81c3-35cf0cfa1567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'bigscience/bloom-7b1'\n",
    "#model_id = 'bigscience/mt0-large'\n",
    "#model_id = 'tiiuae/falcon-7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b257b357-efe5-4c4e-8df2-5b206441e505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664972a3-acb4-497a-8679-2e240f9d620d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e64c4663cd4aac8cb73b7254033df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6d89c7c954457f8b0c05eea3946626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dcf98ae8ff4273b6dc712eb64e2feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f08642c0184c5ca4fd4f29289fbfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/739 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9489355d54044c19cadbed761abeafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/27.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f8a152279545d9be84c9e94a90ce38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dccfd46a094710b0561c3fdba712af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288cbd2bf92f481ea0f6461463d554ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c5cdbf58094f019394b151f85dabc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "#model_id = 'merged'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map='auto', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b7301f-130c-4f3c-9e36-c0fec5860851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310b1078-3210-4794-bc21-0b14da3b44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c44abd-9ad6-4ca5-a072-1f112a548181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"thanhnew2001/alpaca_vn\")\n",
    "\n",
    "data = data.map(\n",
    "    lambda samples: {\n",
    "        \"input_text\": ' ### Human: ' + samples[\"question\"] + ' ### Assisstant: ' + samples[\"answer\"] + ' ### '\n",
    "    }\n",
    ", remove_columns= ['question', 'answer'])\n",
    "\n",
    "data = data.map(lambda examples: tokenizer(examples[\"input_text\"]), batched=True)\n",
    "\n",
    "\n",
    "#print(data['train'])\n",
    "#data['train'][0:5]\n",
    "\n",
    "#data = data.map(lambda x: tokenizer(f\"{x['question']}\"), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd98d9f-8c4e-4235-a1d1-5343e0830734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "# needed for gpt-neo-x tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=2,\n",
    "        max_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5dd46-e194-418b-8ae0-ece229394e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('adapter-model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cdcb056-096f-4e14-9988-ed39c292c01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c00a0b79e2c4bae832ac5ddb8409a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running merge_and_unload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('merged2/tokenizer_config.json',\n",
       " 'merged2/special_tokens_map.json',\n",
       " 'merged2/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel    \n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        return_dict=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, 'adapter-model').to('cuda')\n",
    "print(f\"Running merge_and_unload\")\n",
    "model = model.merge_and_unload() \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model.save_pretrained(\"merged2\")\n",
    "tokenizer.save_pretrained(\"merged2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357dfe0-2695-44ba-baaf-7f010e90b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id ='merged2'\n",
    "model_double = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6974c6ae-55dd-4f14-af56-d2fe55d9aa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 52676,   4822,   5541,  32670,   6131, 101289,  11926,     34, 104300,\n",
      "          14674,   9449,   1120,  20596,   4959,  17382,   3377,   8484,  10960,\n",
      "           1123,   4959,  17382,   3377,   3067,   4850,   6205,   1353,   3339,\n",
      "           3173,     17,  76069,  11075,   6757,   6205,   1353,   3339,   3173,\n",
      "           2001,   1123,   6205,   1353,   3339,  26772,   2001,  11283,   6783,\n",
      "           5301,   4850,   6205,   7350,     17,  76069,  11075,   6757,   6205,\n",
      "           1353,   3339,  32670,   6131, 101289,  11926,   1123,  26772,   2001,\n",
      "           3067,   5301,  12788,  17837,     17,  76069,  11075,   6757,   6205,\n",
      "           1353,   3339,   3173,   2001,   1123,   6205,   1353,   3339,  26772,\n",
      "           2001,  11283,   6783,   5301,   4850,   6205,   7350,     17,  76069,\n",
      "          11075,   6757,   6205,   1353,   3339,  32670,   6131, 101289,  11926,\n",
      "           1123,  26772,   2001,   3067,   5301,  12788,  17837,     17,  76069,\n",
      "          11075,   6757,   6205,   1353,   3339,   3173,   2001,   1123,   6205,\n",
      "           1353,   3339,  26772,   2001,  11283,   6783,   5301,   4850,   6205,\n",
      "           7350,     17,  76069,  11075,   6757,   6205,   1353,   3339,  32670,\n",
      "           6131, 101289,  11926,   1123,  26772,   2001,   3067,   5301,  12788,\n",
      "          17837,     17,  76069,  11075,   6757,   6205,   1353,   3339,   3173,\n",
      "           2001,   1123,   6205,   1353,   3339,  26772,   2001,  11283,   6783,\n",
      "           5301,   4850,   6205,   7350,     17,  76069,  11075,   6757,   6205,\n",
      "           1353,   3339,  32670,   6131, 101289,  11926,   1123,  26772,   2001,\n",
      "           3067,   5301,  12788,  17837,     17,  76069,  11075,   6757,   6205,\n",
      "           1353,   3339,   3173,   2001,   1123,   6205,   1353,   3339,  26772,\n",
      "           2001,  11283,   6783,   5301,   4850,   6205,   7350,     17,  76069,\n",
      "          11075]], device='cuda:0')\n",
      "Làm thế nào vượt qua nghịch cảnh? Câu trả lời là hãy tin tưởng vào bản thân và tin tưởng vào những gì bạn có thể làm. Hãy nhớ rằng bạn có thể làm được và bạn có thể đạt được bất cứ điều gì bạn muốn. Hãy nhớ rằng bạn có thể vượt qua nghịch cảnh và đạt được những điều tốt đẹp. Hãy nhớ rằng bạn có thể làm được và bạn có thể đạt được bất cứ điều gì bạn muốn. Hãy nhớ rằng bạn có thể vượt qua nghịch cảnh và đạt được những điều tốt đẹp. Hãy nhớ rằng bạn có thể làm được và bạn có thể đạt được bất cứ điều gì bạn muốn. Hãy nhớ rằng bạn có thể vượt qua nghịch cảnh và đạt được những điều tốt đẹp. Hãy nhớ rằng bạn có thể làm được và bạn có thể đạt được bất cứ điều gì bạn muốn. Hãy nhớ rằng bạn có thể vượt qua nghịch cảnh và đạt được những điều tốt đẹp. Hãy nhớ rằng bạn có thể làm được và bạn có thể đạt được bất cứ điều gì bạn muốn. Hãy nhớ\n"
     ]
    }
   ],
   "source": [
    "text = \"Làm thế nào vượt qua nghịch cảnh?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", return_token_type_ids=False).to(\"cuda:0\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=200, pad_token_id=50256)\n",
    "print(outputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe9d29-a420-4322-a20d-6315765d8049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
